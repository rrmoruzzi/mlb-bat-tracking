{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16faf3a",
   "metadata": {},
   "source": [
    "## Building models for batting average\n",
    "\n",
    "From the notebook 1-MLB-predictions-EDA, I noticed that, of the features:\n",
    "- features_new = ['avg_swing_speed', 'fast_swing_rate', 'blasts_contact', 'blasts_swing',\n",
    "       'squared_up_contact', 'squared_up_swing', 'avg_swing_length', 'swords']\n",
    "\n",
    "'blast_swing', 'blast contact', 'squared up', 'squared up swings', 'swords' correlate most with average. I also noticed that blast_swing and blast_contact correlate, similarly sqaured up swings and contact. We will still include all of these in the initial model exploration. \n",
    "\n",
    "Also, of the following quality of at bat features:\n",
    "- features_quality = ['exit_velocity_avg', 'launch_angle_avg', 'sweet_spot_percent', 'barrel',\n",
    "       'barrel_batted_rate', 'solidcontact_percent', 'flareburner_percent',\n",
    "       'poorlyunder_percent', 'poorlytopped_percent', 'poorlyweak_percent',\n",
    "       'hard_hit_percent']\n",
    "\n",
    "'exit velo','sweet spot percentage','barrel','flareburner percentage','hard hit percentage','poorly topped','poorly under','poorly weak' correlate most with average. \n",
    "\n",
    "For which model we will use, we will build models using only new features since I am interested in what features most contribute to batting average, then one using new fatures + quality at bat features to see overall, what features contribute most to batting average. To do this: \n",
    "- Models we will use:\n",
    "    - Linear Regression with new tracking stats, then one with both. Using this method since we do want interpretability of which features are important to batting. \n",
    "    - Find features using PCA, then build Regression model. We can use this just as a predictor of batting average. \n",
    "    - Find a regression model using Huber Regularization since there are some outliers in the data. \n",
    "    - Lasso Regression to see which features are more important.\n",
    "- Compare the previous models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8eb4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, Huber\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "76491c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is data from the start of the 2024 season, until 5/14/2024.\n",
    "## it includes those columbs listed below. Need to update this data set. \n",
    "features_new = ['blasts_swing', 'blasts_contact', 'squared_up_swing', 'squared_up_contact', 'swords']\n",
    "features_quality = ['exit_velocity_avg','launch_angle_avg','sweet_spot_percent','barrel','barrel_batted_rate','solidcontact_percent',\n",
    "                    'flareburner_percent','poorlyunder_percent','poorlytopped_percent','poorlyweak_percent','hard_hit_percent']\n",
    "\n",
    "features = features_new + features_quality\n",
    "\n",
    "batters = pd.read_csv('../updated_batter_data.csv')\n",
    "\n",
    "batters = batters[features + ['batting_avg']]\n",
    "\n",
    "batters = batters.dropna(subset = features)\n",
    "# batters.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "78eee42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 17)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "166376bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split data\n",
    "batters_train, batters_test = train_test_split(batters,\n",
    "                                              shuffle = True,\n",
    "                                              random_state = 555, \n",
    "                                              test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bae25fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(s):\n",
    "    power_set = [[]]\n",
    "    for x in s:\n",
    "        power_set += [s0+[x] for s0 in power_set]\n",
    "    return power_set[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a8b1713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = ['baseline']\n",
    "all_models.extend(powerset(features_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "27cb5610",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(5,\n",
    "             shuffle = True,\n",
    "             random_state = 555)\n",
    "\n",
    "mses = np.zeros((5, len(all_models)))\n",
    "\n",
    "for i, (train_index, train_test) in enumerate(kfold.split(batters_train)):\n",
    "    batters_tt = batters_train.iloc[train_index]\n",
    "    batters_ho = batters_train.iloc[train_test]\n",
    "    \n",
    "    for j, subset in enumerate(all_models):\n",
    "        ## baseline prediction \n",
    "        if subset == 'baseline':\n",
    "            subset = np.mean(batters_tt.batting_avg)*np.ones(len(batters_ho.batting_avg))\n",
    "        \n",
    "            mses[i,j] = mean_squared_error(batters_ho.batting_avg.values, subset)\n",
    "        else:\n",
    "            if len(subset) == 1:\n",
    "                model1 = LinearRegression()\n",
    "            \n",
    "                model1.fit(batters_tt[subset].values.reshape(-1,1), \n",
    "                           batters_tt.batting_avg)\n",
    "            \n",
    "                pred = model1.predict(batters_ho[subset].values.reshape(-1,1))\n",
    "            \n",
    "                mses[i,j] = mean_squared_error(batters_ho.batting_avg.values.reshape(-1,1), pred)\n",
    "                \n",
    "            else: \n",
    "                model1 = LinearRegression()\n",
    "            \n",
    "                model1.fit(batters_train[subset].values, \n",
    "                           batters_train.batting_avg.values)\n",
    "            \n",
    "                pred = model1.predict(batters_ho[subset].values)\n",
    "                \n",
    "                mses[i,j] = mean_squared_error(batters_ho.batting_avg.values, pred)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "9e148bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00383842 0.00352362 0.00364635 0.00322763 0.0035902  0.00326434\n",
      " 0.00333155 0.0031921  0.00373704 0.00337398 0.00349032 0.00321713\n",
      " 0.00345601 0.00308695 0.00306058 0.00303867 0.00372918 0.00331356\n",
      " 0.0034431  0.00314716 0.00337786 0.00316171 0.00321963 0.00309713\n",
      " 0.00353427 0.00328679 0.00339255 0.00312933 0.0033074  0.00298973\n",
      " 0.00296215 0.00293257]\n",
      "the minimum mean squared error is:  0.0029325746182761367\n",
      "---\n",
      "the subset that gave this smallest errorr is:\n",
      "['blasts_swing', 'blasts_contact', 'squared_up_swing', 'squared_up_contact', 'swords']\n"
     ]
    }
   ],
   "source": [
    "mses_arr = np.mean(mses,axis = 0)\n",
    "print(mses_arr)\n",
    "print('the minimum mean squared error is: ', mses_arr.min())\n",
    "print('---')\n",
    "print('the subset that gave this smallest errorr is:')\n",
    "print(all_models[mses_arr.argmin()])\n",
    "error_dict = {'best subset error': mses_arr.min()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b89d88fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best subset error': 0.0029325746182761367}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70beb472",
   "metadata": {},
   "source": [
    "### Now we will attempt to use Lasso Regression, PCA, and Huber Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f123b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb1963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d1790a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024_new",
   "language": "python",
   "name": "erdos_may_2024_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
